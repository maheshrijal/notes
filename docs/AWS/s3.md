---
title: Amazon S3
date: 2023-03-16
---

# Amazon S3 (Simple Storage Service)

- S3 allows to store objects (files) in buckets (directories)
- **Bucket names are gloablly unique** (across all AWS accounts)
- Buckets are defined at region level
- Max bucket size is 5TB (5000 GB)
- If uploading more than 5GB use "multi-part upload"
- S3 bucket cannot be mounted

!!! warning "Bucket Limit"
    Bucket have a soft limit of 100 & hard limit of 1000 per account, but no object limits.


## Amazon S3: Security

**User Based**

- **Iam Policies** - API calls allowed or denied for speciric users

**Resource Based**

- **Bucket Policies** - Bucket wide rules from the S3 console - allows cross account (most common)

- **Object Access Control Lists (ACL)** - finer grained (can be disabled)

- **Bucket Access Control Lists (ACL)** - less common (can be disabled)

Access Control Lists are legacy and should be rarely used.

### S3 Bucket Policies

A bucket policy is a type resource policy. Simple use case for bucket policy: Grant anonymous access to the bucket or grant access to other AWS accounts.

!!! note policies

    Identity policy control what an identity can access & can only be attached to the current AWS account. Resource Policy control who can access the resource and can reference other aws accounts for ALLOW/DENY. Resource policies can be used to open a bucket to the public by referencing anonymous principals in the policy.

- JSON based policies
- Effect: Allow/Deny
- Actions: Set of API to allow or deny
- Principal: The account or user to apply the policy to

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "AllowAccessToAccount1",
      "Effect": "Allow",
      "Principal": {
        "AWS": "arn:aws:iam::123456789012:root"
      }, // Only resouce policies have the `Principal` in the policy statement.
      "Action": [
        "s3:GetObject",
        "s3:PutObject"
      ],
      "Resource": "arn:aws:s3:::my-bucket/*"
    }
  ]
}
```

## Amazon S3: Replication

There are 2 types of (asynchronous) replication with S3: CRR (Cross region replication) & SRR (Same Region Replication)

- To enable replication, versioning must be enabled in source & destination buckets.
- Buckets that are to be replicated can be in different aws accounts.
- Buckets must have appropriate IAM permissions to read & write to the destination bucket.
- Once replication is enabled, only new objets are replicated. (To replicated existing objects, S3 batch replication can be used.)

!!! warning "Replication Chaining"

    There is no chaining of replication. If bucket 1 has replication to bucket 2 and bucket 2 has replication to bucket 3, then objects created in bucket 1 are not replicated to bucket 3.

There is a option to enable Delete marker replication. This will also replicate the delete markers across buckets. Only delete markers are replicated and not actual deletes.


## Amazon S3: Durability & Availability

- High durability (99.999999999% or 11 9's) . On average for 10 million objects stored, you can expect to loose 1 object once every 10,000 years. Durability is same for all storage classes.

- Availability S3 Standard: 99.99% availability = 53 minutes downtime per year


## Amazon S3: Storage Classes

### S3 Standard - General Purpose

- 99.99 % availability
- Used for frequently accessed data
- Low latency & high throughput
- Can sustain 2 concurrent facility failures

### S3 Infrequent Access

- Used for data that is less frequently accessed, but requires rapid access when needed
- Lower cost than S3 standard, but chargeable for data retrieval

**Amazon S3 Standard-Infrequent Access (S3 Standard IA)**

- 99.99% availability
- Use cases: Disaster recovery, backups

**Amazon S3 One Zone-Infrequent Access (S3 One Zone IA)**

- Single AZ; datais lost if AZ is destroyed
- 99.5 % availability
- Use Cases: Storing secondary backup copies of on-premise data, or data that can be recreated

### Amzon S3 Glacier

- Low cost object storage meant for archiving/backup
- Pricing: Pay for Storage + Object retrieval cost

There are 3 Classes of Storage within Glacier

**Glacier Instant Retrieval**

- Millisecond retrieval, great for data accessed once a quarter
- Minimum storage duration is 90 days

**Glacier Flexible Retrieval**

- Retrieval Options: Expedited (1-3 Mins), Standard (3-5 hours), Bulk (5 - 12 ours)
- Minimum storage duration is 90 days

**Glacier Deep Archive**

- Retrieval Options: Standard (12 hours), Bulk (48 hours)
- Lowest Cost
- Minimum Storage Duration of 180 days

### S3 Intelligent-Tiering

- Small monthly monitoring & auto-tiering fee
- Moves objects automatically between access tiers based on usage
- There are no charges for retrieval

Tiers:

- Frequent Access (automatic) : Default
- Infrequent Access (automatic): objects not accessed for 30 days
- Archive Instant Access (automatic) : Objects not accessed for 90 days
- Archive Access Tier (optional): Configurable from 90 days to 700+ days
- Deep Archive Access Tier (optional): Configurable from 180 days to 700+ days


## Amazon S3: Encryption

!!! warning

    Buckets are not encrypted. Objects in buckets are encrypted.

### SSE-C

- Server side encryption using keys fully managed by the customer outside AWS
- Amazon S3 does not store the encryption key you provide
- HTTPS must be used
- Encryptiuon key must be provided in http header for every request

### SSE / SSE-S3

- Encryption using keys handled, managed, & owned by AWS
- Object is encrypted server side
- Encryption type is AES-256
- Must set header "x-amz"server-side-encryption":"AES256"
- Enabled by default for new buckets & new objects
- Limitation: Does not have support role seperation

### SSE-KMS

- Encryption using keys handled & managed by AWS KMS
- Advantages: Control = Audit key usage using cloudtrail
- Object is encrypted serer side
- Must set header "x-amz-server-side-encryption":"aws:kms"

Limitation:

- While using SSE-KMS you may be impacted by KMS limits
- When you upload, it calls the GenerateDataKey KMS API
- When you download it call the Decrypt API
- Each of the API calls counts towards the KMS quota per second (5500,10000, 30000 req/s based on region. ). This can be increased using the service quotas console.

### Client-Side Encryption

- Use client libraries such as Amazon S3 Client-Side Encryption Library
- Clients must encrypt/decrypt data themselves before sending/retrieving to S3
- Customer manages the keys & encryption cycle

### Encryption in transit (SSL/TLS)

Encryption in flight is also called SSL/TLS

- Amazon S3 exposes 2 endpoints:
  - HTTP endpoint
  - HTTPS endpoint

- HTTPS is recommended & is mandatory for SSE-C
- Most clients would use https by default

!!! note

    Fore encryption in transit with a bucket policy.
    ```json
    {
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Deny",
            "Principal": "*",
            "Action": "s3:GetObject",
            "Resource": "arn:aws:s3:::your-bucket-name",
            "Condition": {
                "Bool": {
                    "aws:SecureTransport": "false"
    ```

## S3: CORS

- Cross-Origin Resource Sharing (CORS)
- Origin = scheme(protocol) + host (domain) + port. Eg: https://maheshrjl.com [Protocol - https, port - 443, host - maheshrjl.com]
- CORS allows web browser to make requests to other origins while visiting the main origin.
- CORS must be allowed explicitly with CORS Header - [Access-Control-Allow-Origin].

## MFA Delete

- MFA delete forces users to generate code on a MFA decvice before doing important operations.
- To use MFA delete, versionining must be enabled on the bucket.
- Only the bucket owner(root account) can enable/disable MFA delete through AWS CLI.
- Once Enabled: MFA will be required for Enabling versions & suspending versionining on the bucket.

## Access Logs

This option is called Server Access Loging in bucket properties.

- Request made to S3, from any account, authorized or denied will be logged into another S3 bucket.
- The target logging bucket must be in the same AWS region.

!!! warning
    Never set your logging bucket to be the monitored bucket. This creates a logging loop & your bucket will grow exponentially.

## Pre-Signed URL

- Pre Singed URLs can be created with S3 console or AWS CLI
- Users given a Pre-signed URL inherit the permissions of the user that generated the URL for GET/PUT
- URL Expiration:
    - S3 console: 1 minute - 720 minutes
    - AWS CLI: Configure expiration with --expires-in parameter in seconds. Default 3600 secs, max 168 hours

## Vault & Object Locks

### Glacier Vault Lock

- Adopt a WORM (Write Once Read Many) model for S3 glacier vault
- To enable: create a Vault lock policy & then lock the policy for future edits. (Can no longer be changed or deleted)
- Helpful for compliance & data retention

### S3 Object Versionning

- Once enabled versionining cannot be disabled, only suspended.
- When versioning is disabled, ID of the object is set to `null`
- When a object with versioning is deleted, S3 will add a delete marker to the object.

### S3 Object Lock

Versioning must be enabled before enabling object lock.

- Adopt a WORM (Write Once Read Many)
- Block an object version deletion for a specified amount of time.
- **Retention Period**: Protects the object for fixed period, it can be extended.
- **Legal Hold**: Protects the object indefintely, independedent from retention period. Legal Hold can be freely placed & removed using the `s3:PutObjectLegalHold` IAM permission.

**Retention Mode - Compliance**

- Object versions can't be overwritten or deleted by any user, including root user.
- Object retention modes can't be changed, and retion periods can't be shortened

**Retention Mode - Governance**

- Most users can't overwrite, delete or alter an object version or it's lock
- Some users have special permissions to change the retention or delete the object.

## S3: Performance Optimization

**Multipart Upload**

- Minimum data size of 100 MB for multipart upload
- Upload split upto a max of 10,000 parts ranging from 5MB-5GB (Last part is left over & can be smaller than 5GB)
- Each individual upload part can fail in isoloation & restart in isolation
- Much better transfer rates

**Accelerated Transfer**

- Global transfer to S3 might not always take the most direct path
- Use the AWS Edge Locations to speed up transfer
- Bucket name cannot contain periods & it must be DNS compatible to use Transfer Acceleration

## Access Points

Access Points simplify security management for large S3 buckets. Each access point has the following:

- Each access points has it's on DNS name (Internet Origin or VPC Origin)
- An access point policy (similar to bucket policy)  to manage security at scale.

**S3 Access Point - VPC Origin**

- We can define the access point to be accessible only from within the VPC
- You must create a VPC endpoint to access the Access Point (Gateway/Internet Endpoint)
- The VPC Endpoint Policy must allow access to the target bucket & Access Point

## S3 Object Lambda

- Use AWS Lambda functions to change the object before it is retrieved by the caller application.
- Only 1 S3 bucket is needed, on top of which we create S3 Access Point & S3 Object Lambda Access Points.

Use Cases:

  - Redact PII for analytics or non-production environments.
  - Converting across data formats, such as converting XML to JSON
  - Resizing & watermarking images on the fly using caller-specific details